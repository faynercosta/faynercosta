{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMVKzCsme8U/m4SaRBajMq0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/faynercosta/faynercosta/blob/main/Poker_Player.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we need to preprocess the data from the log files into a format that can be used to train the deep learning model. We will create a function to parse the log files and extract relevant information, such as players' hole cards, community cards, and actions taken by the players.\n",
        "\n",
        "Here's a function to parse the log files:"
      ],
      "metadata": {
        "id": "DR0U4N0W_hze"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "0g7jsBdl05rL"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "\n",
        "def parse_log_files(folder_path):\n",
        "    data = []\n",
        "\n",
        "    for file in os.listdir(folder_path):\n",
        "        if file.endswith(\".log\"):\n",
        "            with open(os.path.join(folder_path, file), \"r\") as f:\n",
        "                for line in f:\n",
        "                    if line.startswith(\"STATE\"):\n",
        "                        match = re.match(\n",
        "                            r\"STATE:(\\d+):([\\w\\d\\/]+):([\\w\\d|\\/]+):([\\d\\-\\|]+):([\\w\\|]+)\",\n",
        "                            line.strip(),\n",
        "                        )\n",
        "                        if match:\n",
        "                            hand_idx, actions, cards, money, names = match.groups()\n",
        "                            data.append(\n",
        "                                {\n",
        "                                    \"hand_idx\": int(hand_idx),\n",
        "                                    \"actions\": actions,\n",
        "                                    \"cards\": cards,\n",
        "                                    \"money\": list(map(int, money.split(\"|\"))),\n",
        "                                    \"names\": names.split(\"|\"),\n",
        "                                }\n",
        "                            )\n",
        "    return data\n",
        "\n",
        "# Replace 'root_folder' with the actual path of the folder containing the log files\n",
        "log_data = parse_log_files(\"raw_data\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have the data in a structured format, we can preprocess it further by converting the cards and actions into numerical representations. To do this, we can create a dictionary for card ranks and suits, and another dictionary for actions:"
      ],
      "metadata": {
        "id": "T--t0cIS_lpF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RANKS = {'2': 0, '3': 1, '4': 2, '5': 3, '6': 4, '7': 5, '8': 6, '9': 7, 'T': 8, 'J': 9, 'Q': 10, 'K': 11, 'A': 12}\n",
        "SUITS = {'c': 0, 'd': 1, 'h': 2, 's': 3}\n",
        "ACTIONS = {'f': 0, 'c': 1, 'r': 2}\n",
        "\n",
        "def convert_card_to_numeric(card):\n",
        "    rank, suit = card[0], card[1]\n",
        "    return 4 * RANKS[rank] + SUITS[suit]\n",
        "\n",
        "def convert_action_to_numeric(action):\n",
        "    return ACTIONS[action[0]]\n",
        "\n",
        "def preprocess_data(log_data):\n",
        "    preprocessed_data = []\n",
        "    for hand in log_data:\n",
        "        preprocessed_hand = {\n",
        "            \"hand_id\": hand[\"hand_idx\"],\n",
        "            \"actions\": [convert_action_to_numeric(a) for a in hand[\"actions\"] if a in ACTIONS],\n",
        "            \"hole_cards\": [list(map(convert_card_to_numeric, cards.split('|'))) for cards in hand[\"cards\"].split('/')[0].split('|')],\n",
        "            \"community_cards\": list(map(convert_card_to_numeric, re.findall(r'[\\w\\d]{2}', hand[\"cards\"].split('/')[1]))) if len(hand[\"cards\"].split('/')) > 1 else [],\n",
        "            \"money\": hand[\"money\"],\n",
        "            \"names\": hand[\"names\"],\n",
        "        }\n",
        "        preprocessed_data.append(preprocessed_hand)\n",
        "    return preprocessed_data\n",
        "\n",
        "preprocessed_data = preprocess_data(log_data)\n",
        "\n"
      ],
      "metadata": {
        "id": "OUOtiBE-12bR"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print((preprocessed_data[:3]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GhKuRZfH18Ov",
        "outputId": "315dcf3e-5619-4520-832c-ec4c228f10bc"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'hand_id': 0, 'actions': [0, 0, 2, 0, 2, 0, 0], 'hole_cards': [[37], [12], [44], [8], [48], [18]], 'community_cards': [], 'money': [325, -100, 0, 0, -225, 0], 'names': ['MrPink', 'Eddie', 'MrOrange', 'Bill', 'MrBlue', 'Pluribus']}, {'hand_id': 1, 'actions': [0, 2, 0, 0, 1, 0, 1, 2, 0], 'hole_cards': [[35], [27], [3], [10], [22], [42]], 'community_cards': [17, 41, 16], 'money': [-225, -100, 0, 325, 0, 0], 'names': ['Eddie', 'MrOrange', 'Bill', 'MrBlue', 'Pluribus', 'MrPink']}, {'hand_id': 2, 'actions': [0, 0, 2, 0, 2, 0, 2, 2, 1], 'hole_cards': [[51], [38], [16], [19], [46], [17]], 'community_cards': [22, 49, 24], 'money': [50, -100, 0, 0, 50, 0], 'names': ['MrOrange', 'Bill', 'MrBlue', 'Pluribus', 'MrPink', 'Eddie']}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(inputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qo651e4x1-NF",
        "outputId": "58448dfd-068b-4e39-d4ff-3fe3aaacba48"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The next step is to create a deep learning model using advanced techniques to play Texas Hold'em Poker. To achieve this, we will use a recurrent neural network (RNN) with LSTM (Long Short-Term Memory) cells to process the sequential data. We will use the Keras library, which is part of TensorFlow, to build and train the model. First, let's import the necessary libraries:"
      ],
      "metadata": {
        "id": "s5ud7Czn_ep7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n"
      ],
      "metadata": {
        "id": "fCPcJYYd_tmX"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's prepare the data for the model. We need to create input and output data from the preprocessed data. The input data will consist of the actions, hole cards, community cards, and money, while the output data will be the next action taken by the model:"
      ],
      "metadata": {
        "id": "9NDRHpsk_uf6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_action_length = max([len(hand[\"actions\"]) for hand in preprocessed_data])\n",
        "\n",
        "def create_dataset(preprocessed_data, max_action_length, max_community_cards):\n",
        "    X = []\n",
        "    y = []\n",
        "\n",
        "    for hand in preprocessed_data:\n",
        "        for i in range(len(hand[\"actions\"]) - 1):\n",
        "            padded_actions = hand[\"actions\"][:i + 1] + [-1] * (max_action_length - (i + 1))\n",
        "            flattened_hole_cards = [card for sublist in hand[\"hole_cards\"] for card in sublist]\n",
        "            padded_community_cards = hand[\"community_cards\"] + [-1] * (max_community_cards - len(hand[\"community_cards\"]))\n",
        "            input_data = (\n",
        "                padded_actions +\n",
        "                flattened_hole_cards +\n",
        "                padded_community_cards +\n",
        "                hand[\"money\"]\n",
        "            )\n",
        "            output_data = hand[\"actions\"][i + 1]\n",
        "\n",
        "            X.append(input_data)\n",
        "            y.append(output_data)\n",
        "\n",
        "    return np.array(X, dtype=object), np.array(y, dtype=object)\n",
        "\n",
        "max_community_cards = max(len(hand[\"community_cards\"]) for hand in preprocessed_data)\n",
        "X, y = create_dataset(preprocessed_data, max_action_length, max_community_cards)\n"
      ],
      "metadata": {
        "id": "NtkoUz-5_v4b"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Now, we need to normalize the input data and split it into training and testing sets:\n",
        "scaler = MinMaxScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n"
      ],
      "metadata": {
        "id": "kLxqweA1_yQO"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have the preprocessed train and test data, let's create a deep learning model to play Texas Hold'em Poker using TensorFlow and Keras. We'll use a neural network architecture that leverages LSTM layers to handle the sequential nature of the data.\n",
        "\n",
        "First, let's import the necessary libraries.\n",
        "\n",
        "Then,let's create the model:\n",
        "\n"
      ],
      "metadata": {
        "id": "MIzDHpG4CjXm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout\n"
      ],
      "metadata": {
        "id": "loGx3Pk-AEtX"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_poker_model(input_shape, num_actions):\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(128, input_shape=input_shape, return_sequences=True))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(LSTM(64))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(32, activation='relu'))\n",
        "    model.add(Dense(num_actions, activation='softmax'))\n",
        "\n",
        "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "num_actions = 3\n",
        "input_shape = (1, X_train.shape[1])\n",
        "poker_model = build_poker_model(input_shape, num_actions)\n"
      ],
      "metadata": {
        "id": "GE1GjU8SCbyw"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Now, let's reshape the training and testing data for input into the LSTM layers:\n",
        "X_train_reshaped = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])\n",
        "X_test_reshaped = X_test.reshape(X_test.shape[0], 1, X_test.shape[1])\n"
      ],
      "metadata": {
        "id": "b_JTLNXPCnMQ"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#adjusting label types\n",
        "y_train = y_train.astype('int32')\n",
        "y_test = y_test.astype('int32')\n",
        "\n",
        "#Training the model:\n",
        "epochs = 10\n",
        "batch_size = 64\n",
        "\n",
        "history = poker_model.fit(X_train_reshaped, y_train, validation_data=(X_test_reshaped, y_test), epochs=epochs, batch_size=batch_size)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OcbulCWXCtFD",
        "outputId": "b210648e-ef05-4449-9910-5a994e7df0bd"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1016/1016 [==============================] - 25s 20ms/step - loss: 0.7870 - accuracy: 0.6631 - val_loss: 0.7406 - val_accuracy: 0.6794\n",
            "Epoch 2/10\n",
            "1016/1016 [==============================] - 22s 21ms/step - loss: 0.7091 - accuracy: 0.6939 - val_loss: 0.6850 - val_accuracy: 0.7030\n",
            "Epoch 3/10\n",
            "1016/1016 [==============================] - 21s 21ms/step - loss: 0.6726 - accuracy: 0.7071 - val_loss: 0.6624 - val_accuracy: 0.7106\n",
            "Epoch 4/10\n",
            "1016/1016 [==============================] - 19s 18ms/step - loss: 0.6524 - accuracy: 0.7140 - val_loss: 0.6331 - val_accuracy: 0.7196\n",
            "Epoch 5/10\n",
            "1016/1016 [==============================] - 19s 19ms/step - loss: 0.6315 - accuracy: 0.7190 - val_loss: 0.6114 - val_accuracy: 0.7300\n",
            "Epoch 6/10\n",
            "1016/1016 [==============================] - 22s 22ms/step - loss: 0.6153 - accuracy: 0.7232 - val_loss: 0.6024 - val_accuracy: 0.7228\n",
            "Epoch 7/10\n",
            "1016/1016 [==============================] - 19s 18ms/step - loss: 0.6057 - accuracy: 0.7255 - val_loss: 0.5933 - val_accuracy: 0.7299\n",
            "Epoch 8/10\n",
            "1016/1016 [==============================] - 18s 18ms/step - loss: 0.5983 - accuracy: 0.7242 - val_loss: 0.5901 - val_accuracy: 0.7279\n",
            "Epoch 9/10\n",
            "1016/1016 [==============================] - 20s 19ms/step - loss: 0.5920 - accuracy: 0.7273 - val_loss: 0.5802 - val_accuracy: 0.7351\n",
            "Epoch 10/10\n",
            "1016/1016 [==============================] - 21s 20ms/step - loss: 0.5877 - accuracy: 0.7292 - val_loss: 0.5784 - val_accuracy: 0.7334\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = poker_model.evaluate(X_test_reshaped, y_test)\n",
        "print(\"Test Loss:\", loss)\n",
        "print(\"Test Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GGb_aInSDAwI",
        "outputId": "7ca73b91-9a36-4b94-ba2a-b5a5c1822212"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "508/508 [==============================] - 4s 8ms/step - loss: 0.5784 - accuracy: 0.7334\n",
            "Test Loss: 0.5784344673156738\n",
            "Test Accuracy: 0.7334153652191162\n"
          ]
        }
      ]
    }
  ]
}