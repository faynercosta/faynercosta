{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/faynercosta/faynercosta/blob/main/Video_Preparation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Accessing a YouTube video's transcript: There's a Python library called youtube_transcript_api that can be used to fetch the transcript of a YouTube video. The script will get this in text format.\n",
        "\n",
        "2. Splitting the transcript into segments and sending them to OpenAI: Once we have the transcript, we'll segment it based on time and send each segment as a prompt to OpenAI. You'll need to have an OpenAI API key to do this.\n",
        "\n",
        "3. Receiving the responses from OpenAI and cutting the video: OpenAI will return a list of timestamps that denote the most striking short portions of the video. We can use moviepy, a Python library, to cut the video based on these timestamps and download the clips.\n",
        "\n",
        "Here is the Python code that accomplishes these tasks:"
      ],
      "metadata": {
        "id": "LjK4CR_A2iXi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install youtube_transcript_api\n",
        "!pip install openai\n",
        "!pip install moviepy\n",
        "!pip install pytube\n",
        "\n",
        "from youtube_transcript_api import YouTubeTranscriptApi\n",
        "import openai\n",
        "from moviepy.video.io.ffmpeg_tools import ffmpeg_extract_subclip\n",
        "from pytube import YouTube\n",
        "import json\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sNJradqj2iFq",
        "outputId": "ff636127-7e0b-417d-bb32-d8b95712dd48"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting youtube_transcript_api\n",
            "  Downloading youtube_transcript_api-0.6.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from youtube_transcript_api) (2.27.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->youtube_transcript_api) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->youtube_transcript_api) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->youtube_transcript_api) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->youtube_transcript_api) (3.4)\n",
            "Installing collected packages: youtube_transcript_api\n",
            "Successfully installed youtube_transcript_api-0.6.1\n",
            "Collecting openai\n",
            "  Downloading openai-0.27.8-py3-none-any.whl (73 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.27.8\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.10/dist-packages (1.0.3)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.65.0)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.27.1)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.1.10)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from moviepy) (1.22.4)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.25.1)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.4.8)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio<3.0,>=2.5->moviepy) (8.4.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.4)\n",
            "Collecting pytube\n",
            "  Downloading pytube-15.0.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pytube\n",
            "Successfully installed pytube-15.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import json\n",
        "from pytube import YouTube\n",
        "from youtube_transcript_api import YouTubeTranscriptApi\n",
        "from moviepy.video.io.ffmpeg_tools import ffmpeg_extract_subclip\n",
        "\n",
        "# Set OpenAI API key\n",
        "openai.api_key = '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'\n",
        "\n",
        "def download_video(video_url):\n",
        "    yt = YouTube(video_url)\n",
        "\n",
        "    # Get the highest resolution video stream\n",
        "    video_stream = yt.streams.get_highest_resolution()\n",
        "\n",
        "    # Get the audio stream\n",
        "    #audio_stream = yt.streams.get_audio_only()\n",
        "\n",
        "    # Download the video and audio streams\n",
        "    video_stream.download(filename='video.mp4')\n",
        "    #audio_stream.download(filename='audio.mp4')\n",
        "\n",
        "    # Return the filenames of the downloaded files\n",
        "    return 'video.mp4', 'audio.mp4'\n",
        "\n",
        "def get_transcript(video_id):\n",
        "    transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
        "    return transcript\n",
        "\n",
        "def process_transcript(transcript):\n",
        "    # Construct a formatted transcript for GPT-4\n",
        "    processed_transcript = \"\"\n",
        "    for entry in transcript:\n",
        "        processed_transcript += f\"{entry['start']} - {entry['start'] + entry['duration']}: {entry['text']}\\n\"\n",
        "        print(\"processed transcript: \", processed_transcript)\n",
        "    return processed_transcript\n",
        "\n",
        "\n",
        "def split_into_chunks(processed_transaction, max_tokens):\n",
        "    # Calculate the number of tokens per chunk\n",
        "    tokens_per_chunk = max_tokens/4  # Assuming 1 token is approximately 4 characters\n",
        "\n",
        "    # Split the processed transaction into lines\n",
        "    lines = processed_transaction.split('\\n')\n",
        "\n",
        "    # Initialize an empty list to store the chunks\n",
        "    chunks = []\n",
        "\n",
        "    # Initialize variables for the current chunk\n",
        "    pre_chunk = \"\"\n",
        "    pre_chunk_tokens = 0\n",
        "\n",
        "    # Iterate over the lines\n",
        "    for line in lines:\n",
        "        # Calculate the number of tokens in the line\n",
        "        line_tokens = len(line) // 4\n",
        "\n",
        "        # Check if adding the line would exceed the tokens_per_chunk limit\n",
        "        if pre_chunk_tokens + line_tokens <= tokens_per_chunk:\n",
        "            # Add the line to the pre_chunk\n",
        "            pre_chunk += line + '\\n'\n",
        "            pre_chunk_tokens += line_tokens\n",
        "        else:\n",
        "            # Append the pre_chunk to the chunks list\n",
        "            chunks.append(pre_chunk.rstrip())\n",
        "\n",
        "            # Reset the pre_chunk with the current line\n",
        "            pre_chunk = line + '\\n'\n",
        "            pre_chunk_tokens = line_tokens\n",
        "\n",
        "    # Add the remaining pre_chunk to the chunks list if not empty\n",
        "    if pre_chunk:\n",
        "        chunks.append(pre_chunk.rstrip())\n",
        "\n",
        "    # Return the list of chunks\n",
        "    return chunks\n",
        "\n",
        "\n",
        "def analyze_transcript(chunks):\n",
        "    timestamps = []\n",
        "    chunk = ''\n",
        "\n",
        "    for chunk in chunks:\n",
        "        prompt = f\"\"\"Remember: [The lenght you choose must be between 30s and 60s, and the content be complete enough on and in itself so that it will be impacting and abstract, but also informative]. Here is the portion of the text for you to analyze:\n",
        "\n",
        "{chunk}\n",
        "\n",
        "You must return your response with no text other than the formatted JSON array of dictionaries, where each dictionary has 'start' and 'end' as keys and the corresponding timestamps in seconds as values, such as:\n",
        "\n",
        "[\n",
        "    {{\"start\": INITIAL_TIME, \"end\": END_TIME\"}},\n",
        "    {{\"start\": INITIAL_TIME, \"end\": END_TIME\"}},\n",
        "    {{\"start\": INITIAL_TIME, \"end\": END_TIME\"}},\n",
        "]\n",
        "\"\"\"\n",
        "\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=\"gpt-3.5-turbo-16k\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"I have a transcript from a YouTube video and I would like to identify the two most striking short moments of the video. [Must be a thoughtful and intriguing content that will go viral, consider that multiple lines are required to go above 30 seconds, but full content must not exceed 60 seconds]. Inform just the beggining and the end time]\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ],\n",
        "            max_tokens=max_tokens\n",
        "        )\n",
        "        print(response)\n",
        "        try:\n",
        "            chunk_timestamps = json.loads(response['choices'][0]['message']['content'].strip())\n",
        "            timestamps.extend(chunk_timestamps)\n",
        "        except:\n",
        "            print(\"Failed to parse response as JSON.\")\n",
        "            continue\n",
        "\n",
        "    ### Get the best 5 in terms of lenght\n",
        "    filtered_timestamps = [timestamp for timestamp in timestamps if (timestamp['end'] - timestamp['start']) <= 60]\n",
        "    sorted_timestamps = sorted(filtered_timestamps, key=lambda x: x['end'] - x['start'], reverse=True)\n",
        "    return sorted_timestamps[:5]\n",
        "\n",
        "def cut_video(timestamps):\n",
        "    i = 0\n",
        "    for timestamp in timestamps:\n",
        "        start_time = max(0, timestamp['start'] - 0.5)\n",
        "        filename = f\"clip{i}.mp4\"\n",
        "        ffmpeg_extract_subclip(\"video.mp4\", start_time, timestamp['end']+0.5, targetname=filename)\n",
        "        i += 1\n",
        "\n",
        "video_url = 'https://www.youtube.com/watch?v=oYp5XuGYqqY'\n",
        "#input(\"Enter YouTube Video URL: \")\n",
        "video_id = video_url.split('=')[-1]\n",
        "\n",
        "download_video(video_url)\n",
        "transcript = get_transcript(video_id)\n",
        "processed_transcript = process_transcript(transcript)\n",
        "\n",
        "\n",
        "    # Reserve tokens for the prompt and overhead\n",
        "api_overhead = 3000  # Number of tokens to reserve for API request overhead\n",
        "max_tokens = 8192 - api_overhead  # Adjusted value to accommodate the prompt and other elements\n",
        "chunks = split_into_chunks(processed_transcript, max_tokens)\n",
        "\n",
        "timestamps = analyze_transcript(chunks)\n",
        "cut_video(timestamps)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nArLchlnWhOQ",
        "outputId": "8bfb35f4-bf91-4543-9631-2a2d779565e7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"id\": \"chatcmpl-7c9bLGdjxgSqx8Q9hCqUT0D49wnuE\",\n",
            "  \"object\": \"chat.completion\",\n",
            "  \"created\": 1689327727,\n",
            "  \"model\": \"gpt-3.5-turbo-16k-0613\",\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"index\": 0,\n",
            "      \"message\": {\n",
            "        \"role\": \"assistant\",\n",
            "        \"content\": \"[\\n    {\\\"start\\\": 14.901, \\\"end\\\": 19.313},\\n    {\\\"start\\\": 213.704, \\\"end\\\": 217.928}\\n]\"\n",
            "      },\n",
            "      \"finish_reason\": \"stop\"\n",
            "    }\n",
            "  ],\n",
            "  \"usage\": {\n",
            "    \"prompt_tokens\": 1924,\n",
            "    \"completion_tokens\": 36,\n",
            "    \"total_tokens\": 1960\n",
            "  }\n",
            "}\n",
            "{\n",
            "  \"id\": \"chatcmpl-7c9bNdH76xQ6trCfjx3qRD5yqeBhL\",\n",
            "  \"object\": \"chat.completion\",\n",
            "  \"created\": 1689327729,\n",
            "  \"model\": \"gpt-3.5-turbo-16k-0613\",\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"index\": 0,\n",
            "      \"message\": {\n",
            "        \"role\": \"assistant\",\n",
            "        \"content\": \"[\\n    {\\\"start\\\": 301.47, \\\"end\\\": 314.61699999999996},\\n    {\\\"start\\\": 438.694, \\\"end\\\": 482.369}\\n]\"\n",
            "      },\n",
            "      \"finish_reason\": \"stop\"\n",
            "    }\n",
            "  ],\n",
            "  \"usage\": {\n",
            "    \"prompt_tokens\": 1932,\n",
            "    \"completion_tokens\": 40,\n",
            "    \"total_tokens\": 1972\n",
            "  }\n",
            "}\n",
            "{\n",
            "  \"id\": \"chatcmpl-7c9bO3I8eWxKw0ISfMGYtMNLKGhjY\",\n",
            "  \"object\": \"chat.completion\",\n",
            "  \"created\": 1689327730,\n",
            "  \"model\": \"gpt-3.5-turbo-16k-0613\",\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"index\": 0,\n",
            "      \"message\": {\n",
            "        \"role\": \"assistant\",\n",
            "        \"content\": \"[\\n    {\\\"start\\\": 654.255, \\\"end\\\": 665.6600000000001},\\n    {\\\"start\\\": 808.448, \\\"end\\\": 821.845}\\n]\"\n",
            "      },\n",
            "      \"finish_reason\": \"stop\"\n",
            "    }\n",
            "  ],\n",
            "  \"usage\": {\n",
            "    \"prompt_tokens\": 1905,\n",
            "    \"completion_tokens\": 40,\n",
            "    \"total_tokens\": 1945\n",
            "  }\n",
            "}\n",
            "{\n",
            "  \"id\": \"chatcmpl-7c9bPYOy74OsZiEOQGQ0uoXwgWlev\",\n",
            "  \"object\": \"chat.completion\",\n",
            "  \"created\": 1689327731,\n",
            "  \"model\": \"gpt-3.5-turbo-16k-0613\",\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"index\": 0,\n",
            "      \"message\": {\n",
            "        \"role\": \"assistant\",\n",
            "        \"content\": \"[\\n    {\\\"start\\\": 899.597, \\\"end\\\": 901.69},\\n    {\\\"start\\\": 1116.432, \\\"end\\\": 1118.052}\\n]\"\n",
            "      },\n",
            "      \"finish_reason\": \"stop\"\n",
            "    }\n",
            "  ],\n",
            "  \"usage\": {\n",
            "    \"prompt_tokens\": 1939,\n",
            "    \"completion_tokens\": 38,\n",
            "    \"total_tokens\": 1977\n",
            "  }\n",
            "}\n",
            "{\n",
            "  \"id\": \"chatcmpl-7c9bPaxcZYn8rkpe8kLJham2pAWyN\",\n",
            "  \"object\": \"chat.completion\",\n",
            "  \"created\": 1689327731,\n",
            "  \"model\": \"gpt-3.5-turbo-16k-0613\",\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"index\": 0,\n",
            "      \"message\": {\n",
            "        \"role\": \"assistant\",\n",
            "        \"content\": \"[\\n    {\\\"start\\\": 1123.979, \\\"end\\\": 1137.86},\\n    {\\\"start\\\": 1215.572, \\\"end\\\": 1223.193}\\n]\"\n",
            "      },\n",
            "      \"finish_reason\": \"stop\"\n",
            "    }\n",
            "  ],\n",
            "  \"usage\": {\n",
            "    \"prompt_tokens\": 1608,\n",
            "    \"completion_tokens\": 40,\n",
            "    \"total_tokens\": 1648\n",
            "  }\n",
            "}\n",
            "Moviepy - Running:\n",
            ">>> \"+ \" \".join(cmd)\n",
            "Moviepy - Command successful\n",
            "Moviepy - Running:\n",
            ">>> \"+ \" \".join(cmd)\n",
            "Moviepy - Command successful\n",
            "Moviepy - Running:\n",
            ">>> \"+ \" \".join(cmd)\n",
            "Moviepy - Command successful\n",
            "Moviepy - Running:\n",
            ">>> \"+ \" \".join(cmd)\n",
            "Moviepy - Command successful\n",
            "Moviepy - Running:\n",
            ">>> \"+ \" \".join(cmd)\n",
            "Moviepy - Command successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Working! Next step is to record the line by line document on a variable, in order to set a subtitle in portuguese, see how to post it on twitter"
      ],
      "metadata": {
        "id": "fpyb3Smxfq0H"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}